{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets generate the validation sets\n",
    "As we are going to use Gradient Descent to train the NN we need to scale the data.</br>\n",
    "To scale in a range of 0-1 we will divide each element by 255 (maximum value). To make sure we get the result as a float we need to divide by 255.0 instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = 255.0\n",
    "validation_samples = 5000\n",
    "x_valid, x_train = x_train_full[:validation_samples] / max_value, x_train_full[validation_samples:] / max_value\n",
    "y_valid, y_train = y_train_full[:validation_samples], y_train_full[validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value in Y represents an objet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "We are creating a Sequential Model. This is the simplest kind of keras model. It consists of a stack of layers sequentially connected, thus its name. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation=keras.activations.relu))\n",
    "model.add(keras.layers.Dense(100, activation=keras.activations.relu))\n",
    "model.add(keras.layers.Dense(10 , activation=keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture:\n",
    "Layer1: Flatten layer. Intput layer that will convert each input into a 1D array (x.reshape(-1,1)).\n",
    "\n",
    "Layer2: Dense layer. Hidden layer containing all the conecting weights between inputs and the neurons. It uses ReLU as its activation function (hw.b(X) = ACT(XW+B))\n",
    "\n",
    "Layer3: Dense layer. Hidden layer with 100 neurons with ReLU activation function.\n",
    "\n",
    "Layer4: Dense later. Output layer with 1 neuron per output (10). It uses the SoftMax activation function because the clases are exclusive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively we can initialise the model as a list of layers:\n",
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(100, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(10 , activation=keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "We will use sparse_categorical_crossentropy loss because we have a sparse labels (each target class has a unique index). If we had a OneHotMatrix instead, we would use categorical_cossentropy loss. For binary classification we would use sigmoid instead of softmax in the output layer and binary_crossentropy loss.\n",
    "\n",
    "When using sdg optimizer we are telling Keras to train the model using StocasticGradientDescent when performing the backpropagation algorithm (reverse-mode autodiff). By default sdg optimizer has a learning rate of 0.01. This can be tuned.\n",
    "\n",
    "#### NOTE:\n",
    "Use keras.utils.to_categorical() function to convert sparse labels to OneHotVectors.</br>\n",
    "To go the other way around, use np.argmax() function with axis=1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=[keras.metrics.sparse_categorical_accuracy]\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.7319 - sparse_categorical_accuracy: 0.7581 - val_loss: 0.5169 - val_sparse_categorical_accuracy: 0.8318\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.4882 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.4397 - val_sparse_categorical_accuracy: 0.8550\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.4418 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.4162 - val_sparse_categorical_accuracy: 0.8568\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.4157 - sparse_categorical_accuracy: 0.8522 - val_loss: 0.4259 - val_sparse_categorical_accuracy: 0.8500\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.3956 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.3830 - val_sparse_categorical_accuracy: 0.8644\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3801 - sparse_categorical_accuracy: 0.8660 - val_loss: 0.4018 - val_sparse_categorical_accuracy: 0.8560\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3672 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.3583 - val_sparse_categorical_accuracy: 0.8774\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3549 - sparse_categorical_accuracy: 0.8722 - val_loss: 0.3483 - val_sparse_categorical_accuracy: 0.8782\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.3445 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.3396 - val_sparse_categorical_accuracy: 0.8786\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3354 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.3571 - val_sparse_categorical_accuracy: 0.8724\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.3281 - sparse_categorical_accuracy: 0.8815 - val_loss: 0.3362 - val_sparse_categorical_accuracy: 0.8828\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3198 - sparse_categorical_accuracy: 0.8851 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8738\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.3120 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.3530 - val_sparse_categorical_accuracy: 0.8728\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.3056 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.3293 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.2995 - sparse_categorical_accuracy: 0.8921 - val_loss: 0.3495 - val_sparse_categorical_accuracy: 0.8780\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.2933 - sparse_categorical_accuracy: 0.8949 - val_loss: 0.3193 - val_sparse_categorical_accuracy: 0.8854\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2878 - sparse_categorical_accuracy: 0.8967 - val_loss: 0.3373 - val_sparse_categorical_accuracy: 0.8784\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2816 - sparse_categorical_accuracy: 0.8980 - val_loss: 0.3060 - val_sparse_categorical_accuracy: 0.8912\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.2780 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.3090 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2723 - sparse_categorical_accuracy: 0.9019 - val_loss: 0.3304 - val_sparse_categorical_accuracy: 0.8772\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2694 - sparse_categorical_accuracy: 0.9025 - val_loss: 0.3281 - val_sparse_categorical_accuracy: 0.8812\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2632 - sparse_categorical_accuracy: 0.9048 - val_loss: 0.3184 - val_sparse_categorical_accuracy: 0.8854\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2585 - sparse_categorical_accuracy: 0.9065 - val_loss: 0.3166 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2554 - sparse_categorical_accuracy: 0.9081 - val_loss: 0.3028 - val_sparse_categorical_accuracy: 0.8910\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2502 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.3046 - val_sparse_categorical_accuracy: 0.8904\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.2450 - sparse_categorical_accuracy: 0.9113 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.2413 - sparse_categorical_accuracy: 0.9128 - val_loss: 0.3124 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.2371 - sparse_categorical_accuracy: 0.9145 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.2344 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.2983 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.2302 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.8910\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
