{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de bioinform치tica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo vamos a analizar datos de un dataset de bioinform치tica llamado Gen Expression Omnibus (GEO), disponible en el curso virtual y que originalmente fue descargado del siguiente enlace:\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/geo/info/geo_paccess.html#Programs\n",
    "\n",
    "En concreto, utilizaremos el fichero GSD1001_full.soft.txt que presenta los datos de una serie de experimentos en bioinform치tica. El contenido del fichero es una serie de filas con las siguientes columnas separadas por tabuladores:\n",
    "\n",
    "ID_REF - IDENTIFIER - GSM19023 - GSM19024 - GSM19025 - GSM19026 - Gene title - Gene symbol - Gene ID - UniGene title - UniGene symbol - UniGene ID - Nucleotide Title - GI - GenBank Accession - Platform_CLONEID - Platform_ORF - Platform_SPOTID - Chromosome location - Chromosome annotation - GO:Function - GO:Process - GO:Component - GO:Function ID - GO:Process ID - GO:Component ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este ejercicio consiste en calcular la media de la columna GSD19026 pero solamente teniendo en cuenta las filas cuyo campo GenTitle vale angiopoietin-like 4\n",
    "\n",
    "Para una definici칩n del campo GSM19026, se puede consultar el siguiente enlace: \n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM19026 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ejemplo-inicial/bioinformatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/media/notebooks/ejemplo-inicial/bioinformatica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/notebooks/ejemplo-inicial/bioinformatica\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debemos haber descargado el fichero GDS1001_full.soft.txt y dejado en /media/notebooks/ejemplo-inicial/bioinformatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/ejemplobioinformatica/GDS1001_full.soft.txt\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm /tmp/ejemplobioinformatica/*\n",
    "! hdfs dfs -rmdir /tmp/ejemplobioinformatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir /tmp/ejemplobioinformatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -put GDS1001_full.soft.txt /tmp/ejemplobioinformatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    " \n",
    "import sys\n",
    " \n",
    "for line in sys.stdin:\n",
    "  data = line.strip().split(\"\\t\")\n",
    "\n",
    "  if len(data) == 26:\n",
    "    idref, ident, gsm19023, gsd19024, gsd19025, \\\n",
    "    gsd19026, genetitle, genesymbol, geneID, uniGenetitle, \\\n",
    "    uniGenesymbol, uniGeneID, NucleotideTitle, GI, \\\n",
    "    GenBankAccession, PlatformCLONEID, PlatformORF, PlatformSPOTID, \\\n",
    "    Chromosomelocation, Chromosomeannotation, GOFunction,GOProcess, \\\n",
    "    GOComponent, GOFunctionID,  GOProcessID, GOComponentID = data\n",
    "\n",
    "    if genetitle == \"angiopoietin-like 4\":\n",
    "        print \"{0}\\t{1}\".format(genetitle, gsd19026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    " \n",
    "import sys\n",
    " \n",
    "GSDTotal = 0\n",
    "oldKey = None\n",
    "GSDcounter = 0\n",
    "GSDavg = 0\n",
    " \n",
    "# Recorremos los datos de entrada, que estan en formato clave/valor\n",
    "# donde la clave es el genetitle y valor es el de la columna gsd19026\n",
    " \n",
    "for line in sys.stdin:\n",
    "  data_mapped = line.strip().split(\"\\t\")\n",
    "  if len(data_mapped) != 2:\n",
    "    # Algo ha pasado, nos saltamos esta linea\n",
    "    continue\n",
    " \n",
    "  thisKey, thisGSD = data_mapped\n",
    " \n",
    "  GSDTotal += float(thisGSD)\n",
    "  GSDcounter += 1\n",
    "  print thisKey, \"\\t\", thisGSD\n",
    "\n",
    "    \n",
    "GSDavg = GSDTotal/GSDcounter\n",
    "print \"\\nLa media de GSD19026 para las muestras cuyo GenTitle vale angiopoietin-like 4 es ... \\t\", GSDavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/tmp/salida-ejemplobioinformatica/*': No such file or directory\n",
      "rmdir: `/tmp/salida-ejemplobioinformatica': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm  /tmp/salida-ejemplobioinformatica/*\n",
    "! hdfs dfs -rmdir /tmp/salida-ejemplobioinformatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.15.1.jar] /tmp/streamjob5596744979984745312.jar tmpDir=null\n",
      "19/08/12 06:55:42 INFO client.RMProxy: Connecting to ResourceManager at yarnmaster/172.21.0.3:8032\n",
      "19/08/12 06:55:43 INFO client.RMProxy: Connecting to ResourceManager at yarnmaster/172.21.0.3:8032\n",
      "19/08/12 06:55:43 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "19/08/12 06:55:43 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "19/08/12 06:55:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1565590814059_0003\n",
      "19/08/12 06:55:43 INFO impl.YarnClientImpl: Submitted application application_1565590814059_0003\n",
      "19/08/12 06:55:43 INFO mapreduce.Job: The url to track the job: http://yarnmaster:8088/proxy/application_1565590814059_0003/\n",
      "19/08/12 06:55:43 INFO mapreduce.Job: Running job: job_1565590814059_0003\n",
      "19/08/12 06:55:49 INFO mapreduce.Job: Job job_1565590814059_0003 running in uber mode : false\n",
      "19/08/12 06:55:49 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "19/08/12 06:55:54 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "19/08/12 06:55:59 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/08/12 06:55:59 INFO mapreduce.Job: Job job_1565590814059_0003 completed successfully\n",
      "19/08/12 06:55:59 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=118\n",
      "\t\tFILE: Number of bytes written=442834\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=13276461\n",
      "\t\tHDFS: Number of bytes written=203\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5857\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2169\n",
      "\t\tTotal time spent by all map tasks (ms)=5857\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2169\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5857\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2169\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=5997568\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2221056\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=12489\n",
      "\t\tMap output records=4\n",
      "\t\tMap output bytes=104\n",
      "\t\tMap output materialized bytes=124\n",
      "\t\tInput split bytes=240\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=124\n",
      "\t\tReduce input records=4\n",
      "\t\tReduce output records=6\n",
      "\t\tSpilled Records=8\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=194\n",
      "\t\tCPU time spent (ms)=1810\n",
      "\t\tPhysical memory (bytes) snapshot=796954624\n",
      "\t\tVirtual memory (bytes) snapshot=7918333952\n",
      "\t\tTotal committed heap usage (bytes)=768606208\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=13276221\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=203\n",
      "19/08/12 06:55:59 INFO streaming.StreamJob: Output directory: /tmp/salida-ejemplobioinformatica\n"
     ]
    }
   ],
   "source": [
    "! hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "-files mapper.py,reducer.py -mapper mapper.py -reducer reducer.py \\\n",
    "-input /tmp/ejemplobioinformatica/* \\\n",
    "-output /tmp/salida-ejemplobioinformatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angiopoietin-like 4 \t124.4\r\n",
      "angiopoietin-like 4 \t634.3\r\n",
      "angiopoietin-like 4 \t767.2\r\n",
      "angiopoietin-like 4 \t125.5\r\n",
      "\t\r\n",
      "La media de GSD19026 para las muestras cuyo GenTitle vale angiopoietin-like 4 es ... \t412.85\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /tmp/salida-ejemplobioinformatica/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
