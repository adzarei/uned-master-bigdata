{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - Adrian Jose Zapater Reig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1.2: País con el número de clientes buenos mas alto.\n",
    "Ejemplo de mapreduce en python que devuelve el país con mas clientes categorizados como \"buenos\".\n",
    "\n",
    "## Output:\n",
    "num_clientes    [\"país\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño\n",
    "\n",
    "¿Cuántos pasos MapReduce son necesarios?\n",
    "\n",
    "¿Qué hace cada función de cada paso?\n",
    "\n",
    "¿Qué datos se pasan de una función a la siguiente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota: \n",
    "Los datos deben estar en la ruta: /media/notebook/datos/\n",
    "\n",
    "Los ficheros de origen necesarios son: countries.csv y clients.csv \n",
    "\n",
    "El directorio de trabajo es /media/notebook/tp1-notebooks/mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /media/notebook/tp1-notebooks/mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/media/notebook/tp1-notebooks/mrjob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/notebook/tp1-notebooks/mrjob\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los ficheros countries.csv y clients.csv se cargan de la carpeta /media/notebook/datos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Code\r",
      "\r\n",
      "Afghanistan,AF\r",
      "\r\n",
      "Åland Islands,AX\r",
      "\r\n",
      "Albania,AL\r",
      "\r\n",
      "Algeria,DZ\r",
      "\r\n",
      "American Samoa,AS\r",
      "\r\n",
      "Andorra,AD\r",
      "\r\n",
      "Angola,AO\r",
      "\r\n",
      "Anguilla,AI\r",
      "\r\n",
      "Antarctica,AQ\r",
      "\r\n",
      "Antigua and Barbuda,AG\r",
      "\r\n",
      "Argentina,AR\r",
      "\r\n",
      "Armenia,AM\r",
      "\r\n",
      "Aruba,AW\r",
      "\r\n",
      "Australia,AU\r",
      "\r\n",
      "Austria,AT\r",
      "\r\n",
      "Azerbaijan,AZ\r",
      "\r\n",
      "Bahamas,BS\r",
      "\r\n",
      "Bahrain,BH\r",
      "\r\n",
      "Bangladesh,BD\r",
      "\r\n",
      "Barbados,BB\r",
      "\r\n",
      "Belarus,BY\r",
      "\r\n",
      "Belgium,BE\r",
      "\r\n",
      "Belize,BZ\r",
      "\r\n",
      "Benin,BJ\r",
      "\r\n",
      "Bermuda,BM\r",
      "\r\n",
      "Bhutan,BT\r",
      "\r\n",
      "\"Bolivia, Plurinational State of\",BO\r",
      "\r\n",
      "\"Bonaire, Sint Eustatius and Saba\",BQ\r",
      "\r\n",
      "Bosnia and Herzegovina,BA\r",
      "\r\n",
      "Botswana,BW\r",
      "\r\n",
      "Bouvet Island,BV\r",
      "\r\n",
      "Brazil,BR\r",
      "\r\n",
      "British Indian Ocean Territory,IO\r",
      "\r\n",
      "Brunei Darussalam,BN\r",
      "\r\n",
      "Bulgaria,BG\r",
      "\r\n",
      "Burkina Faso,BF\r",
      "\r\n",
      "Burundi,BI\r",
      "\r\n",
      "Cambodia,KH\r",
      "\r\n",
      "Cameroon,CM\r",
      "\r\n",
      "Canada,CA\r",
      "\r\n",
      "Cape Verde,CV\r",
      "\r\n",
      "Cayman Islands,KY\r",
      "\r\n",
      "Central African Republic,CF\r",
      "\r\n",
      "Chad,TD\r",
      "\r\n",
      "Chile,CL\r",
      "\r\n",
      "China,CN\r",
      "\r\n",
      "Christmas Island,CX\r",
      "\r\n",
      "Cocos (Keeling) Islands,CC\r",
      "\r\n",
      "Colombia,CO\r",
      "\r\n",
      "Comoros,KM\r",
      "\r\n",
      "Congo,CG\r",
      "\r\n",
      "\"Congo, the Democratic Republic of the\",CD\r",
      "\r\n",
      "Cook Islands,CK\r",
      "\r\n",
      "Costa Rica,CR\r",
      "\r\n",
      "Côte d'Ivoire,CI\r",
      "\r\n",
      "Croatia,HR\r",
      "\r\n",
      "Cuba,CU\r",
      "\r\n",
      "Curaçao,CW\r",
      "\r\n",
      "Cyprus,CY\r",
      "\r\n",
      "Czech Republic,CZ\r",
      "\r\n",
      "Denmark,DK\r",
      "\r\n",
      "Djibouti,DJ\r",
      "\r\n",
      "Dominica,DM\r",
      "\r\n",
      "Dominican Republic,DO\r",
      "\r\n",
      "Ecuador,EC\r",
      "\r\n",
      "Egypt,EG\r",
      "\r\n",
      "El Salvador,SV\r",
      "\r\n",
      "Equatorial Guinea,GQ\r",
      "\r\n",
      "Eritrea,ER\r",
      "\r\n",
      "Estonia,EE\r",
      "\r\n",
      "Ethiopia,ET\r",
      "\r\n",
      "Falkland Islands (Malvinas),FK\r",
      "\r\n",
      "Faroe Islands,FO\r",
      "\r\n",
      "Fiji,FJ\r",
      "\r\n",
      "Finland,FI\r",
      "\r\n",
      "France,FR\r",
      "\r\n",
      "French Guiana,GF\r",
      "\r\n",
      "French Polynesia,PF\r",
      "\r\n",
      "French Southern Territories,TF\r",
      "\r\n",
      "Gabon,GA\r",
      "\r\n",
      "Gambia,GM\r",
      "\r\n",
      "Georgia,GE\r",
      "\r\n",
      "Germany,DE\r",
      "\r\n",
      "Ghana,GH\r",
      "\r\n",
      "Gibraltar,GI\r",
      "\r\n",
      "Greece,GR\r",
      "\r\n",
      "Greenland,GL\r",
      "\r\n",
      "Grenada,GD\r",
      "\r\n",
      "Guadeloupe,GP\r",
      "\r\n",
      "Guam,GU\r",
      "\r\n",
      "Guatemala,GT\r",
      "\r\n",
      "Guernsey,GG\r",
      "\r\n",
      "Guinea,GN\r",
      "\r\n",
      "Guinea-Bissau,GW\r",
      "\r\n",
      "Guyana,GY\r",
      "\r\n",
      "Haiti,HT\r",
      "\r\n",
      "Heard Island and McDonald Islands,HM\r",
      "\r\n",
      "Holy See (Vatican City State),VA\r",
      "\r\n",
      "Honduras,HN\r",
      "\r\n",
      "Hong Kong,HK\r",
      "\r\n",
      "Hungary,HU\r",
      "\r\n",
      "Iceland,IS\r",
      "\r\n",
      "India,IN\r",
      "\r\n",
      "Indonesia,ID\r",
      "\r\n",
      "\"Iran, Islamic Republic of\",IR\r",
      "\r\n",
      "Iraq,IQ\r",
      "\r\n",
      "Ireland,IE\r",
      "\r\n",
      "Isle of Man,IM\r",
      "\r\n",
      "Israel,IL\r",
      "\r\n",
      "Italy,IT\r",
      "\r\n",
      "Jamaica,JM\r",
      "\r\n",
      "Japan,JP\r",
      "\r\n",
      "Jersey,JE\r",
      "\r\n",
      "Jordan,JO\r",
      "\r\n",
      "Kazakhstan,KZ\r",
      "\r\n",
      "Kenya,KE\r",
      "\r\n",
      "Kiribati,KI\r",
      "\r\n",
      "\"Korea, Democratic People's Republic of\",KP\r",
      "\r\n",
      "\"Korea, Republic of\",KR\r",
      "\r\n",
      "Kuwait,KW\r",
      "\r\n",
      "Kyrgyzstan,KG\r",
      "\r\n",
      "Lao People's Democratic Republic,LA\r",
      "\r\n",
      "Latvia,LV\r",
      "\r\n",
      "Lebanon,LB\r",
      "\r\n",
      "Lesotho,LS\r",
      "\r\n",
      "Liberia,LR\r",
      "\r\n",
      "Libya,LY\r",
      "\r\n",
      "Liechtenstein,LI\r",
      "\r\n",
      "Lithuania,LT\r",
      "\r\n",
      "Luxembourg,LU\r",
      "\r\n",
      "Macao,MO\r",
      "\r\n",
      "\"Macedonia, the Former Yugoslav Republic of\",MK\r",
      "\r\n",
      "Madagascar,MG\r",
      "\r\n",
      "Malawi,MW\r",
      "\r\n",
      "Malaysia,MY\r",
      "\r\n",
      "Maldives,MV\r",
      "\r\n",
      "Mali,ML\r",
      "\r\n",
      "Malta,MT\r",
      "\r\n",
      "Marshall Islands,MH\r",
      "\r\n",
      "Martinique,MQ\r",
      "\r\n",
      "Mauritania,MR\r",
      "\r\n",
      "Mauritius,MU\r",
      "\r\n",
      "Mayotte,YT\r",
      "\r\n",
      "Mexico,MX\r",
      "\r\n",
      "\"Micronesia, Federated States of\",FM\r",
      "\r\n",
      "\"Moldova, Republic of\",MD\r",
      "\r\n",
      "Monaco,MC\r",
      "\r\n",
      "Mongolia,MN\r",
      "\r\n",
      "Montenegro,ME\r",
      "\r\n",
      "Montserrat,MS\r",
      "\r\n",
      "Morocco,MA\r",
      "\r\n",
      "Mozambique,MZ\r",
      "\r\n",
      "Myanmar,MM\r",
      "\r\n",
      "Namibia,NA\r",
      "\r\n",
      "Nauru,NR\r",
      "\r\n",
      "Nepal,NP\r",
      "\r\n",
      "Netherlands,NL\r",
      "\r\n",
      "New Caledonia,NC\r",
      "\r\n",
      "New Zealand,NZ\r",
      "\r\n",
      "Nicaragua,NI\r",
      "\r\n",
      "Niger,NE\r",
      "\r\n",
      "Nigeria,NG\r",
      "\r\n",
      "Niue,NU\r",
      "\r\n",
      "Norfolk Island,NF\r",
      "\r\n",
      "Northern Mariana Islands,MP\r",
      "\r\n",
      "Norway,NO\r",
      "\r\n",
      "Oman,OM\r",
      "\r\n",
      "Pakistan,PK\r",
      "\r\n",
      "Palau,PW\r",
      "\r\n",
      "\"Palestine, State of\",PS\r",
      "\r\n",
      "Panama,PA\r",
      "\r\n",
      "Papua New Guinea,PG\r",
      "\r\n",
      "Paraguay,PY\r",
      "\r\n",
      "Peru,PE\r",
      "\r\n",
      "Philippines,PH\r",
      "\r\n",
      "Pitcairn,PN\r",
      "\r\n",
      "Poland,PL\r",
      "\r\n",
      "Portugal,PT\r",
      "\r\n",
      "Puerto Rico,PR\r",
      "\r\n",
      "Qatar,QA\r",
      "\r\n",
      "Réunion,RE\r",
      "\r\n",
      "Romania,RO\r",
      "\r\n",
      "Russian Federation,RU\r",
      "\r\n",
      "Rwanda,RW\r",
      "\r\n",
      "Saint Barthélemy,BL\r",
      "\r\n",
      "\"Saint Helena, Ascension and Tristan da Cunha\",SH\r",
      "\r\n",
      "Saint Kitts and Nevis,KN\r",
      "\r\n",
      "Saint Lucia,LC\r",
      "\r\n",
      "Saint Martin (French part),MF\r",
      "\r\n",
      "Saint Pierre and Miquelon,PM\r",
      "\r\n",
      "Saint Vincent and the Grenadines,VC\r",
      "\r\n",
      "Samoa,WS\r",
      "\r\n",
      "San Marino,SM\r",
      "\r\n",
      "Sao Tome and Principe,ST\r",
      "\r\n",
      "Saudi Arabia,SA\r",
      "\r\n",
      "Senegal,SN\r",
      "\r\n",
      "Serbia,RS\r",
      "\r\n",
      "Seychelles,SC\r",
      "\r\n",
      "Sierra Leone,SL\r",
      "\r\n",
      "Singapore,SG\r",
      "\r\n",
      "Sint Maarten (Dutch part),SX\r",
      "\r\n",
      "Slovakia,SK\r",
      "\r\n",
      "Slovenia,SI\r",
      "\r\n",
      "Solomon Islands,SB\r",
      "\r\n",
      "Somalia,SO\r",
      "\r\n",
      "South Africa,ZA\r",
      "\r\n",
      "South Georgia and the South Sandwich Islands,GS\r",
      "\r\n",
      "South Sudan,SS\r",
      "\r\n",
      "Spain,ES\r",
      "\r\n",
      "Sri Lanka,LK\r",
      "\r\n",
      "Sudan,SD\r",
      "\r\n",
      "Suriname,SR\r",
      "\r\n",
      "Svalbard and Jan Mayen,SJ\r",
      "\r\n",
      "Swaziland,SZ\r",
      "\r\n",
      "Sweden,SE\r",
      "\r\n",
      "Switzerland,CH\r",
      "\r\n",
      "Syrian Arab Republic,SY\r",
      "\r\n",
      "\"Taiwan, Province of China\",TW\r",
      "\r\n",
      "Tajikistan,TJ\r",
      "\r\n",
      "\"Tanzania, United Republic of\",TZ\r",
      "\r\n",
      "Thailand,TH\r",
      "\r\n",
      "Timor-Leste,TL\r",
      "\r\n",
      "Togo,TG\r",
      "\r\n",
      "Tokelau,TK\r",
      "\r\n",
      "Tonga,TO\r",
      "\r\n",
      "Trinidad and Tobago,TT\r",
      "\r\n",
      "Tunisia,TN\r",
      "\r\n",
      "Turkey,TR\r",
      "\r\n",
      "Turkmenistan,TM\r",
      "\r\n",
      "Turks and Caicos Islands,TC\r",
      "\r\n",
      "Tuvalu,TV\r",
      "\r\n",
      "Uganda,UG\r",
      "\r\n",
      "Ukraine,UA\r",
      "\r\n",
      "United Arab Emirates,AE\r",
      "\r\n",
      "United Kingdom,GB\r",
      "\r\n",
      "United States,US\r",
      "\r\n",
      "United States Minor Outlying Islands,UM\r",
      "\r\n",
      "Uruguay,UY\r",
      "\r\n",
      "Uzbekistan,UZ\r",
      "\r\n",
      "Vanuatu,VU\r",
      "\r\n",
      "\"Venezuela, Bolivarian Republic of\",VE\r",
      "\r\n",
      "Viet Nam,VN\r",
      "\r\n",
      "\"Virgin Islands, British\",VG\r",
      "\r\n",
      "\"Virgin Islands, U.S.\",VI\r",
      "\r\n",
      "Wallis and Futuna,WF\r",
      "\r\n",
      "Western Sahara,EH\r",
      "\r\n",
      "Yemen,YE\r",
      "\r\n",
      "Zambia,ZM\r",
      "\r\n",
      "Zimbabwe,ZW\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "cat /media/notebook/datos/countries.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertram Pearcy  ,bueno,SO\r\n",
      "Steven Ulman  ,regular,ZA\r\n",
      "Enid Follansbee  ,malo,GS\r\n",
      "Candie Jacko  ,malo,SS\r\n",
      "Alana Zufelt  ,regular,ES\r\n",
      "Craig Pinkett  ,malo,LK\r\n",
      "Carson Levey  ,bueno,GU\r\n",
      "Reanna Calabrese  ,regular,GT\r\n",
      "Elliott Kosak  ,malo,GG\r\n",
      "Yuette Steinman  ,bueno,GN\r\n",
      "Grisel Wines  ,regular,GW\r\n",
      "Kathryne Dieguez  ,regular,AE\r\n",
      "Donna Raabe  ,malo,GB\r\n",
      "Norine Mundt  ,bueno,US\r\n",
      "Brittaney Amaro  ,bueno,ES\r\n",
      "Penni Husted  ,bueno,ES\r\n",
      "Delmer Semon  ,malo,IT\r\n",
      "Lennie Dunkerson  ,bueno,CA\r\n",
      "Mayra Bobb  ,regular,IT\r\n",
      "Altagracia Merced  ,regular,CA\r\n",
      "Verda Belgrave  ,malo,GB\r\n",
      "Jonnie Urban  ,malo,US\r\n",
      "Chung Frankum  ,malo,ES\r\n",
      "Vincenzo Samples  ,regular,TT\r\n",
      "Dominick Barkan  ,bueno,GU\r\n",
      "Carisa Ellingwood  ,bueno,TR\r\n",
      "Garret Wess  ,regular,TM\r\n",
      "Zoraida Muise  ,bueno,GU\r\n",
      "Samantha Cusson  ,bueno,PT\r\n",
      "Jenine Greenburg  ,regular,PR\r\n",
      "Geri Paddock  ,bueno,QA\r\n",
      "Antonia Klosterman  ,regular,RE\r\n",
      "Moriah Galey  ,malo,RO\r\n",
      "Nyla Eckard  ,malo,GB\r\n",
      "Arlean Harries  ,malo,US\r\n",
      "Kenyatta Lippold  ,malo,ES\r\n",
      "Samuel Knipe  ,malo,MV\r\n",
      "Jamison Starner  ,malo,ML\r\n",
      "Joel Blye  ,regular,MT\r\n",
      "Adela Jaimes  ,regular,GB\r\n",
      "Isis Sorrells  ,regular,US\r\n",
      "Chester Abdul  ,regular,ES\r\n",
      "Manda Wingate  ,regular,SI\r\n",
      "Anna Rappold  ,regular,SB\r\n",
      "Albina Lamore  ,malo,SO\r\n",
      "Carolyn Machado  ,bueno,ZA\r\n",
      "Jeni Espinoza  ,bueno,GS\r\n",
      "Charisse Salzman  ,bueno,SS\r\n",
      "Dorla Silber  ,bueno,ES\r\n",
      "Lilli Bryson  ,malo,LK\r\n"
     ]
    }
   ],
   "source": [
    "cat /media/notebook/datos/clients.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob-ejercicio_1_2.py\n"
     ]
    }
   ],
   "source": [
    " %%writefile mrjob-ejercicio_1_2.py\n",
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRPaisMaxClientesBuenos(MRJob):\n",
    "\n",
    "    # Realiza la ordenacion secundaria\n",
    "    MRJob.SORT_VALUES = True\n",
    "\n",
    "    # Igual que en el ejercicio 1.1\n",
    "    def map_and_filter(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\",\")\n",
    "\n",
    "        if len(splits) == 2: # datos de paises\n",
    "            symbol = 'A' # ordenamos los paises antes que los datos de personas\n",
    "            country2digit = splits[1]\n",
    "            yield country2digit, [symbol, splits]\n",
    "        else: #  datos de personas\n",
    "            if splits[1].lower() == \"bueno\":\n",
    "                symbol = 'B'\n",
    "                country2digit = splits[2]\n",
    "                yield country2digit, [symbol, splits]\n",
    "                \n",
    "    # Igual que en el ejercicio 1.1            \n",
    "    def reducer_join_clients_country(self, key, values):\n",
    "        countries = [] # paises primero ya que llevan la clave 'A'\n",
    "        for value in values:\n",
    "            if value[0] == 'A':\n",
    "                countries.append(value)\n",
    "            if value[0] == 'B':\n",
    "                for country in countries:\n",
    "                    countryName = country[1][0]\n",
    "                    yield [countryName], 1\n",
    "    \n",
    "    # Este reducer se encarga de devolver cada pais y la suma de clientes buenos que tiene.\n",
    "    # Cabe destacar que, como queremos que el resultado de este reducer se trabaje en el mismo reducer, tenemos que\n",
    "    # usar una misma key en el yield. Como no nos importa que key usar, utilizamos 'None'.\n",
    "    # Devolvemos una tupla (Nº total de clientes buenos, pais).\n",
    "    def reducer_count_clients(self, country, counts):\n",
    "        yield None, (sum(counts), country)\n",
    "    \n",
    "    \n",
    "    # Este reducer se encarga de devolver el número máximo de clientes buenos y el pais.\n",
    "    # Aplica la función max de python sobre la lista de tuplas y devuelve la tupla con mas clientes buenos.\n",
    "    # Nota: Sólo devuelve 1 en caso de estar empatados.\n",
    "    def reducer_max_clients_bueno(self, _, country_pair):\n",
    "        yield max(country_pair)\n",
    "        \n",
    "        \n",
    "    # Usamos steps para definir el orden de los mappers y reducers.\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper=self.map_and_filter,\n",
    "                reducer=self.reducer_join_clients_country),\n",
    "            MRStep(\n",
    "                reducer=self.reducer_count_clients\n",
    "            ),\n",
    "            MRStep(\n",
    "                reducer=self.reducer_max_clients_bueno\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRPaisMaxClientesBuenos.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero ejecutamos el código en local y luego en Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/mrjob-ejercicio_1_2.root.20191115.230416.118125\n",
      "Running step 1 of 3...\n",
      "Running step 2 of 3...\n",
      "Running step 3 of 3...\n",
      "job output is in /tmp/mrjob-ejercicio_1_2.root.20191115.230416.118125/output\n",
      "Streaming final output from /tmp/mrjob-ejercicio_1_2.root.20191115.230416.118125/output...\n",
      "Removing temp directory /tmp/mrjob-ejercicio_1_2.root.20191115.230416.118125...\n"
     ]
    }
   ],
   "source": [
    "! python mrjob-ejercicio_1_2.py /media/notebook/datos/countries.csv  \\\n",
    "/media/notebook/datos/clients.csv > ouputlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t[\"Spain\"]\r\n"
     ]
    }
   ],
   "source": [
    "! cat ouputlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir -p /tmp/mrjoin\n",
    "! hdfs dfs -put -f /media/notebook/datos/countries.csv  /tmp/mrjoin\n",
    "! hdfs dfs -put -f /media/notebook/datos/clients.csv  /tmp/mrjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 root supergroup       1289 2019-11-15 23:04 /tmp/mrjoin/clients.csv\r\n",
      "-rw-r--r--   3 root supergroup       4120 2019-11-15 23:04 /tmp/mrjoin/countries.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls  /tmp/mrjoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos la carpeta donde dejaremos la salida del programa en HDFS y su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/carpeta/mrjob-join-output/_SUCCESS\n",
      "Deleted /tmp/carpeta/mrjob-join-output/part-00000\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm /tmp/carpeta/mrjob-join-output/*\n",
    "! hdfs dfs -rmdir /tmp/carpeta/mrjob-join-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /usr/lib/hadoop/bin...\n",
      "Found hadoop binary: /usr/lib/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/mrjob-ejercicio_1_2.root.20191115.230438.143364\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/mrjob-ejercicio_1_2.root.20191115.230438.143364/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/mrjob-ejercicio_1_2.root.20191115.230438.143364/files/\n",
      "Running step 1 of 3...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.15.1.jar] /tmp/streamjob2905431204285557816.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.22.0.2:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.22.0.2:8032\n",
      "  Total input paths to process : 2\n",
      "  number of splits:3\n",
      "  Submitting tokens for job: job_1573858085741_0005\n",
      "  Submitted application application_1573858085741_0005\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1573858085741_0005/\n",
      "  Running job: job_1573858085741_0005\n",
      "  Job job_1573858085741_0005 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1573858085741_0005 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/mrjob-ejercicio_1_2.root.20191115.230438.143364/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=6825\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=257\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=9300\n",
      "\t\tFILE: Number of bytes written=614537\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=7114\n",
      "\t\tHDFS: Number of bytes written=257\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=12\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=3\n",
      "\t\tLaunched map tasks=3\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12884992\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2040832\n",
      "\t\tTotal time spent by all map tasks (ms)=12583\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=12583\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1993\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1993\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12583\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1993\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1820\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=353\n",
      "\t\tInput split bytes=289\n",
      "\t\tMap input records=300\n",
      "\t\tMap output bytes=8794\n",
      "\t\tMap output materialized bytes=9312\n",
      "\t\tMap output records=250\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tPhysical memory (bytes) snapshot=1102782464\n",
      "\t\tReduce input groups=250\n",
      "\t\tReduce input records=250\n",
      "\t\tReduce output records=16\n",
      "\t\tReduce shuffle bytes=9312\n",
      "\t\tShuffled Maps =3\n",
      "\t\tSpilled Records=500\n",
      "\t\tTotal committed heap usage (bytes)=1158676480\n",
      "\t\tVirtual memory (bytes) snapshot=10526720000\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 3...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.15.1.jar] /tmp/streamjob742957473002962690.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.22.0.2:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.22.0.2:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1573858085741_0006\n",
      "  Submitted application application_1573858085741_0006\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1573858085741_0006/\n",
      "  Running job: job_1573858085741_0006\n",
      "  Job job_1573858085741_0006 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1573858085741_0006 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/mrjob-ejercicio_1_2.root.20191115.230438.143364/step-output/0001\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=386\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=307\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=311\n",
      "\t\tFILE: Number of bytes written=447435\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=722\n",
      "\t\tHDFS: Number of bytes written=307\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=5140480\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2085888\n",
      "\t\tTotal time spent by all map tasks (ms)=5020\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5020\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2037\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2037\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5020\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2037\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1150\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=181\n",
      "\t\tInput split bytes=336\n",
      "\t\tMap input records=16\n",
      "\t\tMap output bytes=273\n",
      "\t\tMap output materialized bytes=317\n",
      "\t\tMap output records=16\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=804933632\n",
      "\t\tReduce input groups=12\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=12\n",
      "\t\tReduce shuffle bytes=317\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=32\n",
      "\t\tTotal committed heap usage (bytes)=847773696\n",
      "\t\tVirtual memory (bytes) snapshot=7891456000\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 3 of 3...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.15.1.jar] /tmp/streamjob3387303421668826669.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.22.0.2:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.22.0.2:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1573858085741_0007\n",
      "  Submitted application application_1573858085741_0007\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1573858085741_0007/\n",
      "  Running job: job_1573858085741_0007\n",
      "  Job job_1573858085741_0007 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1573858085741_0007 completed successfully\n",
      "  Output directory: hdfs:///tmp/carpeta/mrjob-join-output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=461\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=12\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=349\n",
      "\t\tFILE: Number of bytes written=447349\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=797\n",
      "\t\tHDFS: Number of bytes written=12\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=5350400\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1956864\n",
      "\t\tTotal time spent by all map tasks (ms)=5225\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5225\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1911\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1911\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5225\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1911\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1110\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=165\n",
      "\t\tInput split bytes=336\n",
      "\t\tMap input records=12\n",
      "\t\tMap output bytes=319\n",
      "\t\tMap output materialized bytes=355\n",
      "\t\tMap output records=12\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=782692352\n",
      "\t\tReduce input groups=12\n",
      "\t\tReduce input records=12\n",
      "\t\tReduce output records=1\n",
      "\t\tReduce shuffle bytes=355\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=24\n",
      "\t\tTotal committed heap usage (bytes)=825229312\n",
      "\t\tVirtual memory (bytes) snapshot=7899267072\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///tmp/carpeta/mrjob-join-output\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/mrjob-ejercicio_1_2.root.20191115.230438.143364...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp directory /tmp/mrjob-ejercicio_1_2.root.20191115.230438.143364...\r\n"
     ]
    }
   ],
   "source": [
    "! python mrjob-ejercicio_1_2.py hdfs:///tmp/mrjoin/* -r hadoop --python-bin /opt/anaconda/bin/python3.7 \\\n",
    "--output-dir hdfs:///tmp/carpeta/mrjob-join-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t[\"Spain\"]\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /tmp/carpeta/mrjob-join-output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
